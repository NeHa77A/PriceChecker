{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import pandas as pd\n",
    "import os\n",
    "from src.PriceChecker.components.data_ingestion import DataScraper\n",
    "from src.PriceChecker.components.data_validation import CSVProcessor\n",
    "from src.PriceChecker.components.data_store import CSVToDatabaseLoader\n",
    "from src.PriceChecker.constant.database import db_config\n",
    "from src.PriceChecker.components.visualization import ModelPriceComparer\n",
    "\n",
    "app = Flask(__name__, template_folder='E:\\\\assignment\\\\templates')\n",
    "\n",
    "def create_directories():\n",
    "    ingestion_dir = 'artifact/data_ingestion'\n",
    "    validation_dir = 'artifact/data_validation'\n",
    "    os.makedirs(ingestion_dir, exist_ok=True)\n",
    "    os.makedirs(validation_dir, exist_ok=True)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route('/scrape', methods=['POST'])\n",
    "def scrape():\n",
    "    query = request.form.get('query')\n",
    "    \n",
    "    if not query:\n",
    "        return jsonify({'error': 'Query parameter missing'}), 400\n",
    "    \n",
    "    datainge = DataScraper()\n",
    "\n",
    "    # Scrape data from both Reliance Digital and Flipkart\n",
    "    reliance_data = datainge.scrape_reliance(query) or []\n",
    "    flipkart_data = datainge.scrape_flipkart(query) or []\n",
    "\n",
    "    if not reliance_data and not flipkart_data:\n",
    "        return jsonify({'error': 'No data extracted from both sources.'}), 500\n",
    "\n",
    "    # Create necessary directories\n",
    "    create_directories()\n",
    "\n",
    "    # Save the raw scraped data to CSV files\n",
    "    reliance_df = pd.DataFrame(reliance_data, columns=['Model Name', 'Price'])\n",
    "    flipkart_df = pd.DataFrame(flipkart_data, columns=['Model Name', 'Price'])\n",
    "    \n",
    "    reliance_raw_path = 'artifact/data_ingestion/reliance_data.csv'\n",
    "    flipkart_raw_path = 'artifact/data_ingestion/flipkart_data.csv'\n",
    "    \n",
    "    reliance_df.to_csv(reliance_raw_path, index=False)\n",
    "    flipkart_df.to_csv(flipkart_raw_path, index=False)\n",
    "\n",
    "    # Clean the data\n",
    "    reliance_processor = CSVProcessor(reliance_raw_path, 'artifact/data_validation/reliance_data.csv')\n",
    "    reliance_processor.clean_csv()\n",
    "\n",
    "    flipkart_processor = CSVProcessor(flipkart_raw_path, 'artifact/data_validation/flipkart_data.csv')\n",
    "    flipkart_processor.clean_csv()\n",
    "\n",
    "    # Load cleaned data to the database\n",
    "    csv_to_table = {\n",
    "        'artifact/data_validation/reliance_data.csv': 'reliance_data',\n",
    "        'artifact/data_validation/flipkart_data.csv': 'flipkart_data'\n",
    "    }\n",
    "\n",
    "    loader = CSVToDatabaseLoader(db_config, csv_to_table)\n",
    "    loader.run()\n",
    "\n",
    "    # Compare and visualize the prices\n",
    "    comparer = ModelPriceComparer()\n",
    "    output_file = 'matched_models_with_prices.csv'\n",
    "    df_matched = comparer.find_matching_names_and_compare_prices(\n",
    "        'artifact/data_validation/reliance_data.csv',\n",
    "        'artifact/data_validation/flipkart_data.csv',\n",
    "        output_file\n",
    "    )\n",
    "\n",
    "    image_path = 'E:\\\\assignment\\\\static\\\\price_comparison.png'\n",
    "    comparer.visualize_price_differences(df_matched, image_path)\n",
    "\n",
    "    # Combine results from both sources for display\n",
    "    combined_data = {\n",
    "        'Reliance Digital': reliance_data,\n",
    "        'Flipkart': flipkart_data\n",
    "    }\n",
    "\n",
    "    return render_template(\"results.html\", data=combined_data, image_path=image_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import pandas as pd\n",
    "import os\n",
    "from src.PriceChecker.components.data_ingestion import DataScraper\n",
    "from src.PriceChecker.components.data_validation import CSVProcessor\n",
    "from src.PriceChecker.components.data_store import CSVToDatabaseLoader,db_config\n",
    "from src.PriceChecker.constant.database import *\n",
    "\n",
    "app = Flask(__name__, template_folder='E:\\\\assignment\\\\templates')\n",
    "\n",
    "def create_directories():\n",
    "    ingestion_dir = 'artifact/data_ingestion'\n",
    "    validation_dir = 'artifact/data_validation'\n",
    "    os.makedirs(ingestion_dir, exist_ok=True)\n",
    "    os.makedirs(validation_dir, exist_ok=True)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route('/scrape', methods=['POST'])\n",
    "def scrape():\n",
    "    query = request.form.get('query')\n",
    "    \n",
    "    if not query:\n",
    "        return jsonify({'error': 'Query parameter missing'}), 400\n",
    "    \n",
    "    datainge = DataScraper()\n",
    "\n",
    "    # Scrape data from both Reliance Digital and Flipkart\n",
    "    reliance_data = datainge.scrape_reliance(query) or []\n",
    "    flipkart_data = datainge.scrape_flipkart(query) or []\n",
    "\n",
    "    if not reliance_data and not flipkart_data:\n",
    "        return jsonify({'error': 'No data extracted from both sources.'}), 500\n",
    "\n",
    "    # Create necessary directories\n",
    "    create_directories()\n",
    "\n",
    "    # Save the raw scraped data to CSV files\n",
    "    reliance_df = pd.DataFrame(reliance_data, columns=['Model Name', 'Price'])\n",
    "    flipkart_df = pd.DataFrame(flipkart_data, columns=['Model Name', 'Price'])\n",
    "    \n",
    "    reliance_raw_path = 'artifact/data_ingestion/reliance_data.csv'\n",
    "    flipkart_raw_path = 'artifact/data_ingestion/flipkart_data.csv'\n",
    "    \n",
    "    reliance_df.to_csv(reliance_raw_path, index=False)\n",
    "    flipkart_df.to_csv(flipkart_raw_path, index=False)\n",
    "\n",
    "    # Clean the data\n",
    "    reliance_processor = CSVProcessor(reliance_raw_path, 'artifact/data_validation/reliance_data.csv')\n",
    "    reliance_processor.clean_csv()\n",
    "\n",
    "    flipkart_processor = CSVProcessor(flipkart_raw_path, 'artifact/data_validation/flipkart_data.csv')\n",
    "    flipkart_processor.clean_csv()\n",
    "\n",
    "    # Load cleaned data to the database\n",
    "    csv_to_table = {\n",
    "        'artifact/data_validation/reliance_data.csv': 'reliance_data',\n",
    "        'artifact/data_validation/flipkart_data.csv': 'flipkart_data'\n",
    "    }\n",
    "\n",
    "    loader = CSVToDatabaseLoader(db_config, csv_to_table)\n",
    "    loader.run()\n",
    "\n",
    "    # Combine results from both sources for display\n",
    "    combined_data = {\n",
    "        'Reliance Digital': reliance_data,\n",
    "        'Flipkart': flipkart_data\n",
    "    }\n",
    "\n",
    "    return render_template(\"results.html\", data=combined_data)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from src.PriceChecker.components.data_ingestion import DataScraper\n",
    "\n",
    "app = Flask(__name__, template_folder='E:\\\\assignment\\\\templates')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route('/scrape', methods=['POST'])\n",
    "def scrape():\n",
    "    query = request.form.get('query')\n",
    "    \n",
    "    if not query:\n",
    "        return jsonify({'error': 'Query parameter missing'}), 400\n",
    "    \n",
    "    datainge = DataScraper()\n",
    "\n",
    "    # Scrape data from both Reliance Digital and Flipkart\n",
    "    reliance_data = datainge.scrape_reliance(query) or []\n",
    "    flipkart_data = datainge.scrape_flipkart(query) or []\n",
    "\n",
    "    if not reliance_data and not flipkart_data:\n",
    "        return jsonify({'error': 'No data extracted from both sources.'}), 500\n",
    "\n",
    "    # Combine results from both sources\n",
    "    combined_data = {\n",
    "        'Reliance Digital': reliance_data,\n",
    "        'Flipkart': flipkart_data\n",
    "    }\n",
    "\n",
    "    return render_template(\"results.html\", data=combined_data)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
